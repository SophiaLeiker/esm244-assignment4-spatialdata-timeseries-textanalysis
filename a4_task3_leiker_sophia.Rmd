---
title: 'Assignment 4 - Task 3: Text Wrangling and Analysis'
author: "Sophia Leiker"
date: "3/11/2022"
output: 
  html_document:
    toc: true
---

```{r setup, include=TRUE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(tidyverse)
library(tidytext)
library(textdata)
library(pdftools)
library(ggwordcloud)
```

## 1. Introduction

This report will wrangle text files and carry out an analysis of most frequent words found in East of Eden and carry out a sentiment analysis on a chapter by chapter basis. 


**Data Source:** The text used for this sentiment analysis is [East of Eden by John Steinback](https://www.goodreads.com/book/show/4406.East_of_Eden). It was published in September 1952, and is based on the lives of two families living in the Salinas valley in California. 


![East of Eden Cover](https://images-na.ssl-images-amazon.com/images/I/91ZuwqPXv6L.jpg){width=50%}

Reading in East of Eden PDF
```{r}
#reading in the data
eden <- pdf_text(here::here('data', 'east_of_eden.pdf'))
```

Checking that the text was read in correctly by testing the page number
```{r}
#testing for page number
eden34 <- eden[34]
```


## 2. Wordcloud

Breaking East of Eden up into lines
```{r}
eden_lines <- data.frame(eden) %>%  #this is breaking it down into each of the pages
  mutate(page = 1:n()) %>% #each row is a page
  mutate(text_full = str_split(eden, pattern = '\\n')) %>% 
  #taking the text of each individual page and breaking up the lines by using the \n line break
  unnest(text_full) %>% 
  mutate(text_full = str_trim(text_full))
```

Breaking East of Eden up into Chapters
```{r}
eden_chapts <- eden_lines %>% 
  slice(-(1:181)) %>% #dropping the first lines 
  mutate(chapter = ifelse(str_detect(text_full, "Chapter"), text_full, NA)) %>% #this is saying if you are in full text column, and detect "Chapter", then save that whole line and save it to the "chapter" column, if you do not then don't do anything 
  fill(chapter, .direction = 'down') %>% #filling for chapters
  separate(col = chapter, into = c("ch", "no"), sep = " ") %>% 
  slice(-(1:2)) %>% 
  mutate(chapter = as.numeric(as.roman(no)))
  #this will separate a column into 2 different columns, take chapter column, separate it into the word chapter, and then the number
```

Analyzing Word Count by Chapter
```{r}
eden_words <- eden_chapts %>% 
  unnest_tokens(word, text_full) %>% 
  select(-eden)
```

```{r}
eden_wordcount <- eden_words %>% 
  count(chapter, word) #grouping by chapter and then word
#new df, for each word in each chapter how many times it shows up
```

Removing Stop Words
```{r}
#head(stop_words)
 
eden_words_clean <- eden_words %>% 
  anti_join(stop_words, by = 'word') 
#takes the stop words and takes out the stopwords (drops all of them)
```

```{r}
nonstop_counts <- eden_words_clean %>% 
  count(chapter, word)

nonstop_counts1 <- nonstop_counts %>% 
  filter(chapter %in% c(1:30))

nonstop_counts2 <- nonstop_counts %>% 
  filter(chapter %in% c(31:55))
```

***

### A. Top 5 Words from Each Chapter
Given this book has over 50 chatpers, for visualization purposes, the chapters are broken up into two sections for analysis. 

#### Chapters 1-30
```{r}
top_5_words1 <- nonstop_counts1 %>% 
  group_by(chapter) %>% 
  arrange(-n) %>% #arranging in decending order by number of words
  slice(1:5) %>% #slicing by 1st through 5th value of each group
  ungroup()
 
# Make some graphs: 
ggplot(data = top_5_words1, aes(x = n, y = word)) +
  geom_col(fill = "blue") +
  facet_wrap(~chapter, scales = "free") +
  labs(title = "Top 5 Words East of Eden by Chapter (Chapters 1-30)", x = "Chapter", y= "Word")

```

**Figure 1**: Top 5 Words East of Eden by chapter after removing stop words. Chapters 1-20 visualized here. 


#### Chatpers 30-55
```{r}
top_5_words2 <- nonstop_counts2 %>% 
  group_by(chapter) %>% 
  arrange(-n) %>% #arranging in descending order by number of words
  slice(1:5) %>% #slicing by 1st through 5th value of each group
  ungroup()
 
# Make some graphs: 
ggplot(data = top_5_words2, aes(x = n, y = word)) +
  geom_col(fill = "blue") +
  facet_wrap(~chapter, scales = "free") +
  labs(title = "Top 5 Words East of Eden by Chapter (Chapters 31-55)", x = "Chapter", y= "Word")
```

**Figure 2**: Top 5 Words East of Eden by chapter after removing stop words. Chapters 31-55 visualized here. 

***

### B.Word Cloud for Chapter 1
```{r}
ch1_top100 <- nonstop_counts %>% 
  filter(chapter == 1) %>% 
  arrange(-n) %>% 
  slice(1:100)
```

```{r}
ch1_cloud <- ggplot(data = ch1_top100, aes(label = word)) +
  geom_text_wordcloud(aes(color = n, size = n), shape = "diamond") +
  #color based on the amount of words
  scale_size_area(max_size = 6) +
  scale_color_gradientn(colors = c("darkgreen","blue","purple")) + #gives a list of colors and then it will create a scale out of this 
  theme_minimal()
 
ch1_cloud
```

**Figure 3**: Wordcloud of East of Eden Chapter 1

***

## 3. Sentiment Analysis

```{r}
get_sentiments(lexicon = "afinn")
get_sentiments(lexicon = "bing")
```


### A. Sentiment analysis with Afinn: 

First, bind words in `hobbit_nonstop_words` to `afinn` lexicon:
```{r}
eden_afinn <- eden_words_clean %>% 
  inner_join(get_sentiments("afinn"), by = 'word')
```

Let's find some counts (by sentiment ranking):
```{r}
afinn_counts <- eden_afinn %>% 
  count(chapter, value)
 
# Plot them: 
#ggplot(data = afinn_counts, aes(x = value, y = n)) +
#  geom_col() +
 # facet_wrap(~chapter)
 
# Find the mean afinn score by chapter: 
afinn_means <- eden_afinn %>% 
  group_by(chapter) %>% 
  summarize(mean_afinn = mean(value))
 
ggplot(data = afinn_means, 
       aes(x = fct_rev(factor(chapter)), #this converts chapter number to be 1-20
           y = mean_afinn)) +
           # y = fct_rev(as.factor(chapter)))) +
  geom_col(aes(fill = mean_afinn)) +
  coord_flip() +
  labs(title = "Sentiment Analysis of East of Eden using Afinn", subtitle = "East of Eden: John Steinback", x = "Chapter", y= "Sentiment") +
  scale_color_gradient() +
  theme(legend.position="none")
  
```

**Figure 4**: Sentiment Analysis of East of Eden using AFINN

***

### B. Sentiment Analysis Using NRC

```{r}
eden_nrc <- eden_words_clean %>% 
  inner_join(get_sentiments("nrc"))
```
Let's find the count of words by chapter and sentiment bin: 

```{r}
eden_nrc_counts <- eden_nrc %>% 
  count(chapter, sentiment)
 
eden_nrc_counts1 <- eden_nrc_counts %>% 
  filter(chapter %in% c(1:30))
 
eden_nrc_counts2 <- eden_nrc_counts %>% 
  filter(chapter %in% c(31:55))


ggplot(data = eden_nrc_counts1, aes(x = sentiment, y = n)) +
  geom_col(fill = "forestgreen") +
  facet_wrap(~chapter) +
  coord_flip() +
  labs(title = "Sentiment Analysis of East of Eden using NRC (Chapters 1-30)", subtitle = "East of Eden: John Steinback", x = "Sentiment", y= "Chapter")
```

**Figure 5**: Sentiment Analysis of East of Eden using AFINN for Chapters 1-30


```{r}
ggplot(data = eden_nrc_counts2, aes(x = sentiment, y = n)) +
  geom_col(fill = "forestgreen") +
  facet_wrap(~chapter) +
  coord_flip() +
  labs(title = "Sentiment Analysis of East of Eden using NRC (Chapters 31-55)", subtitle = "East of Eden: John Steinback", x = "Sentiment", y= "Chapter")
```

**Figure 6**: Sentiment Analysis of East of Eden using AFINN for Chapters 1-30

***

